{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293711d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Notebook gen√©rico de limpieza de datos\n",
    "# ============================================\n",
    "\n",
    "# Librer√≠as necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Cargar CSV\n",
    "# Cambia 'archivo.csv' por tu dataset\n",
    "df = pd.read_csv(\"listings.csv\", encoding=\"utf-8\", sep=\",\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4054a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Exploraci√≥n inicial\n",
    "print(\"Dimensiones del dataset:\", df.shape)\n",
    "display(df.head())\n",
    "df.info()\n",
    "display(df.describe(include=\"all\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c032cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================\n",
    "# 3. Problemas a revisar\n",
    "# ============================================\n",
    "\n",
    "# --- Valores ausentes ---\n",
    "print(\"\\nValores nulos por columna:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cb6304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.query(\"State.isnull()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf47278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Duplicados ---\n",
    "print(\"\\nN√∫mero de filas duplicadas:\", df.duplicated().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1c23e4",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# df[df.duplicated(keep=False)]\n",
    "# df\n",
    "\n",
    "duplicados = df[df.duplicated(keep=False)]\n",
    "\n",
    "# Ordenar por las columnas relevantes\n",
    "duplicados_ordenados = duplicados.sort_values(by=df.columns.tolist())\n",
    "duplicados_ordenados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3d6b42",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Marcar duplicados\n",
    "df['is_duplicate'] = df.duplicated(keep=False)\n",
    "\n",
    "# Filtrar duplicados\n",
    "duplicados_df = df[df['is_duplicate']].copy()\n",
    "\n",
    "# Ordenar por todas las columnas del dataset (excluir la columna is_duplicate)\n",
    "cols_to_sort = [col for col in df.columns if col != 'is_duplicate']\n",
    "duplicados_ordenados = duplicados_df.sort_values(by=cols_to_sort)\n",
    "\n",
    "# Resumen agrupado - agrupar por todas las columnas originales para contar duplicados id√©nticos\n",
    "resumen_duplicados = (\n",
    "    duplicados_df[cols_to_sort]\n",
    "    .value_counts()\n",
    "    .reset_index(name='count')\n",
    "    .sort_values(by='count', ascending=False)\n",
    ")\n",
    "\n",
    "print(f\"Total de filas duplicadas: {len(duplicados_df)}\")\n",
    "print(f\"\\nPrimeros duplicados ordenados (mostrando {min(10, len(duplicados_ordenados))} filas):\")\n",
    "display(duplicados_ordenados.head(10))\n",
    "\n",
    "print(f\"\\nResumen de duplicados (grupos √∫nicos con sus conteos):\")\n",
    "display(resumen_duplicados.head(20))\n",
    "\n",
    "# Limpiar columna temporal\n",
    "df.drop(columns=['is_duplicate'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcgdlbox9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Visualizaci√≥n y an√°lisis de duplicados\n",
    "# ============================================\n",
    "\n",
    "# Solo ejecutar si hay duplicados\n",
    "if df.duplicated().sum() > 0:\n",
    "    # Marcar duplicados nuevamente (temporal)\n",
    "    df_temp = df.copy()\n",
    "    df_temp['is_duplicate'] = df_temp.duplicated(keep=False)\n",
    "    duplicados_temp = df_temp[df_temp['is_duplicate']].copy()\n",
    "    \n",
    "    # 1. Gr√°fico de barras mejorado: Top 10 combinaciones m√°s duplicadas\n",
    "    cols_to_group = [col for col in df.columns]\n",
    "    top_duplicados = (\n",
    "        duplicados_temp[cols_to_group]\n",
    "        .value_counts()\n",
    "        .head(10)\n",
    "        .reset_index(name='frecuencia')\n",
    "    )\n",
    "    \n",
    "    # Crear figura m√°s grande y con mejor distribuci√≥n\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    \n",
    "    # Crear etiquetas m√°s descriptivas y legibles\n",
    "    labels_completas = []\n",
    "    labels_cortas = []\n",
    "    for idx, row in top_duplicados.iterrows():\n",
    "        # Identificar las columnas m√°s relevantes (con valores variados)\n",
    "        label_parts = []\n",
    "        # Limitar a las primeras 4 columnas m√°s relevantes\n",
    "        for i, col in enumerate(cols_to_group[:4]):\n",
    "            val = str(row[col])\n",
    "            # Truncar valores muy largos\n",
    "            if len(val) > 25:\n",
    "                val = val[:22] + \"...\"\n",
    "            label_parts.append(f\"  ‚Ä¢ {col}: {val}\")\n",
    "        \n",
    "        # Etiqueta completa para mostrar debajo del gr√°fico\n",
    "        labels_completas.append(f\"Grupo {idx+1}:\\n\" + \"\\n\".join(label_parts))\n",
    "        # Etiqueta corta para el eje X\n",
    "        labels_cortas.append(f\"Grupo {idx+1}\")\n",
    "    \n",
    "    # Crear gr√°fico de barras con colores degradados\n",
    "    colores = plt.cm.RdYlGn_r(np.linspace(0.3, 0.9, len(top_duplicados)))\n",
    "    barras = ax.bar(range(len(top_duplicados)), top_duplicados['frecuencia'], \n",
    "                    color=colores, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    # Agregar valores en la parte superior de cada barra\n",
    "    for i, (barra, valor) in enumerate(zip(barras, top_duplicados['frecuencia'])):\n",
    "        height = barra.get_height()\n",
    "        ax.text(barra.get_x() + barra.get_width()/2., height,\n",
    "                f'{int(valor)} registros\\nduplicados',\n",
    "                ha='center', va='bottom', fontsize=10, fontweight='bold',\n",
    "                bbox=dict(boxstyle='round,pad=0.5', facecolor='yellow', alpha=0.7))\n",
    "    \n",
    "    # Configurar ejes y t√≠tulo\n",
    "    ax.set_xlabel('Grupos de duplicados', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('N√∫mero de registros duplicados', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Top 10: Registros duplicados m√°s frecuentes\\n(Cu√°ntas veces se repite exactamente la misma informaci√≥n)', \n",
    "                 fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_xticks(range(len(top_duplicados)))\n",
    "    ax.set_xticklabels(labels_cortas, rotation=0, fontsize=11)\n",
    "    \n",
    "    # Agregar grid para mejor lectura\n",
    "    ax.yaxis.grid(True, linestyle='--', alpha=0.7)\n",
    "    ax.set_axisbelow(True)\n",
    "    \n",
    "    # Ajustar l√≠mites del eje Y\n",
    "    ax.set_ylim(0, max(top_duplicados['frecuencia']) * 1.15)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Mostrar leyenda detallada de cada grupo\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"LEYENDA: Detalles de cada grupo de duplicados\")\n",
    "    print(\"=\"*80)\n",
    "    for i, label in enumerate(labels_completas):\n",
    "        print(f\"\\n{label}\")\n",
    "        print(f\"  ‚Üí Total de registros id√©nticos: {int(top_duplicados.iloc[i]['frecuencia'])}\")\n",
    "        print(\"-\" * 80)\n",
    "    \n",
    "    # 2. Tabla cruzada: Analizar duplicados por columnas categ√≥ricas\n",
    "    # Identificar columnas categ√≥ricas con menos de 20 valores √∫nicos\n",
    "    cat_cols = [col for col in df.select_dtypes(include=['object']).columns \n",
    "                if df[col].nunique() < 20 and df[col].nunique() > 1]\n",
    "    \n",
    "    if len(cat_cols) >= 2:\n",
    "        # Crear tabla cruzada con las dos primeras columnas categ√≥ricas\n",
    "        col1, col2 = cat_cols[0], cat_cols[1]\n",
    "        \n",
    "        # Marcar si cada fila es duplicada\n",
    "        df_temp['es_duplicado'] = df_temp.duplicated(keep=False).astype(int)\n",
    "        \n",
    "        # Tabla cruzada: contar duplicados por categor√≠as\n",
    "        tabla_cruzada = pd.crosstab(\n",
    "            df_temp[col1], \n",
    "            df_temp[col2],\n",
    "            values=df_temp['es_duplicado'],\n",
    "            aggfunc='sum',\n",
    "            margins=True,\n",
    "            margins_name='TOTAL'\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"TABLA CRUZADA: Duplicados seg√∫n '{col1}' vs '{col2}'\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"(Muestra cu√°ntos registros duplicados hay para cada combinaci√≥n)\\n\")\n",
    "        display(tabla_cruzada)\n",
    "        \n",
    "        # Heatmap de la tabla cruzada (sin la fila/columna de totales)\n",
    "        if len(tabla_cruzada) > 2:  # Solo si hay suficientes datos\n",
    "            plt.figure(figsize=(14, 10))\n",
    "            sns.heatmap(\n",
    "                tabla_cruzada.iloc[:-1, :-1],  # Excluir fila y columna 'TOTAL'\n",
    "                annot=True, \n",
    "                fmt='g', \n",
    "                cmap='YlOrRd',\n",
    "                cbar_kws={'label': 'Cantidad de duplicados'},\n",
    "                linewidths=0.5,\n",
    "                linecolor='gray'\n",
    "            )\n",
    "            plt.title(f'Mapa de Calor: Concentraci√≥n de duplicados\\nCruce entre {col1} y {col2}\\n(Colores m√°s oscuros = m√°s duplicados)', \n",
    "                     fontsize=14, fontweight='bold', pad=20)\n",
    "            plt.xlabel(col2, fontsize=12, fontweight='bold')\n",
    "            plt.ylabel(col1, fontsize=12, fontweight='bold')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "    # 3. An√°lisis detallado del primer grupo duplicado\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"EJEMPLO DETALLADO: Primer grupo de duplicados encontrado\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"(Mostrando todas las filas que tienen exactamente la misma informaci√≥n)\\n\")\n",
    "    \n",
    "    # Obtener el primer grupo de duplicados\n",
    "    primer_grupo = (\n",
    "        duplicados_temp[cols_to_group]\n",
    "        .value_counts()\n",
    "        .head(1)\n",
    "        .reset_index(name='count')\n",
    "    )\n",
    "    \n",
    "    if len(primer_grupo) > 0:\n",
    "        # Crear filtro para encontrar todas las filas de este grupo\n",
    "        filtros = []\n",
    "        for col in cols_to_group:\n",
    "            valor = primer_grupo.iloc[0][col]\n",
    "            if pd.isna(valor):\n",
    "                filtros.append(df_temp[col].isna())\n",
    "            else:\n",
    "                filtros.append(df_temp[col] == valor)\n",
    "        \n",
    "        # Combinar todos los filtros\n",
    "        filtro_final = filtros[0]\n",
    "        for f in filtros[1:]:\n",
    "            filtro_final = filtro_final & f\n",
    "        \n",
    "        ejemplo_duplicados = df_temp[filtro_final].drop(columns=['is_duplicate', 'es_duplicado'], errors='ignore')\n",
    "        \n",
    "        print(f\"‚úì Este grupo tiene {len(ejemplo_duplicados)} registros id√©nticos\\n\")\n",
    "        print(\"Registros duplicados:\")\n",
    "        display(ejemplo_duplicados)\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"Valores compartidos por todos estos registros duplicados:\")\n",
    "        print(f\"{'='*80}\")\n",
    "        for i, col in enumerate(cols_to_group[:15], 1):  # Mostrar primeras 15 columnas\n",
    "            valor = primer_grupo.iloc[0][col]\n",
    "            print(f\"{i:2}. {col:30} = {valor}\")\n",
    "        \n",
    "        if len(cols_to_group) > 15:\n",
    "            print(f\"\\n... y {len(cols_to_group) - 15} columnas m√°s con valores id√©nticos\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "    # Resumen final\n",
    "    total_duplicados = len(duplicados_temp)\n",
    "    total_registros = len(df_temp)\n",
    "    porcentaje = (total_duplicados / total_registros) * 100\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RESUMEN DE DUPLICADOS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"‚Ä¢ Total de registros en el dataset: {total_registros:,}\")\n",
    "    print(f\"‚Ä¢ Total de registros duplicados: {total_duplicados:,}\")\n",
    "    print(f\"‚Ä¢ Porcentaje de duplicados: {porcentaje:.2f}%\")\n",
    "    print(f\"‚Ä¢ Grupos √∫nicos de duplicados: {len(top_duplicados)}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "else:\n",
    "    print(\"‚úì No se encontraron duplicados en el dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873b7e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# --- Inconsistencias de formato ---\n",
    "# ============================================\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AN√ÅLISIS DE INCONSISTENCIAS DE FORMATO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Funci√≥n para detectar el formato de una fecha\n",
    "def detectar_formato_fecha(valor):\n",
    "    \"\"\"Detecta el formato de una fecha\"\"\"\n",
    "    if pd.isnull(valor):\n",
    "        return 'NULL'\n",
    "    \n",
    "    valor_str = str(valor).strip()\n",
    "    \n",
    "    # Patrones comunes de fecha\n",
    "    patrones = {\n",
    "        'DD/MM/YY': r'^\\d{1,2}/\\d{1,2}/\\d{2}$',\n",
    "        'DD/MM/YYYY': r'^\\d{1,2}/\\d{1,2}/\\d{4}$',\n",
    "        'DD-MM-YY': r'^\\d{1,2}-\\d{1,2}-\\d{2}$',\n",
    "        'DD-MM-YYYY': r'^\\d{1,2}-\\d{1,2}-\\d{4}$',\n",
    "        'YYYY-MM-DD': r'^\\d{4}-\\d{1,2}-\\d{1,2}$',\n",
    "        'YYYY/MM/DD': r'^\\d{4}/\\d{1,2}/\\d{1,2}$',\n",
    "        'MM/DD/YYYY': r'^\\d{1,2}/\\d{1,2}/\\d{4}$',  # Ambiguo con DD/MM/YYYY\n",
    "        'YYYYMMDD': r'^\\d{8}$',\n",
    "        'YYYY-MM-DD HH:MM:SS': r'^\\d{4}-\\d{2}-\\d{2}\\s+\\d{1,2}:\\d{2}:\\d{2}',\n",
    "        'DD/MM/YYYY HH:MM': r'^\\d{1,2}/\\d{1,2}/\\d{4}\\s+\\d{1,2}:\\d{2}',\n",
    "        'ISO8601': r'^\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}',\n",
    "    }\n",
    "    \n",
    "    # Valores especiales\n",
    "    if valor_str == '-' or valor_str == '':\n",
    "        return 'PLACEHOLDER'\n",
    "    \n",
    "    # Buscar coincidencia con patrones\n",
    "    for nombre, patron in patrones.items():\n",
    "        if re.match(patron, valor_str):\n",
    "            return nombre\n",
    "    \n",
    "    # Si contiene n√∫meros y separadores, es formato desconocido\n",
    "    if re.search(r'\\d', valor_str) and re.search(r'[/-:]', valor_str):\n",
    "        return 'FORMATO_DESCONOCIDO'\n",
    "    \n",
    "    return 'NO_FECHA'\n",
    "\n",
    "# Funci√≥n para detectar formato de hora\n",
    "def detectar_formato_hora(valor):\n",
    "    \"\"\"Detecta el formato de una hora\"\"\"\n",
    "    if pd.isnull(valor):\n",
    "        return 'NULL'\n",
    "    \n",
    "    valor_str = str(valor).strip()\n",
    "    \n",
    "    if valor_str == '-' or valor_str == '':\n",
    "        return 'PLACEHOLDER'\n",
    "    \n",
    "    patrones_hora = {\n",
    "        'HH:MM:SS': r'^\\d{1,2}:\\d{2}:\\d{2}$',\n",
    "        'HH:MM': r'^\\d{1,2}:\\d{2}$',\n",
    "        'HHMM': r'^\\d{4}$',\n",
    "        'HH:MM AM/PM': r'^\\d{1,2}:\\d{2}\\s*(AM|PM|am|pm)$',\n",
    "    }\n",
    "    \n",
    "    for nombre, patron in patrones_hora.items():\n",
    "        if re.match(patron, valor_str):\n",
    "            return nombre\n",
    "    \n",
    "    return 'NO_HORA'\n",
    "\n",
    "# Funci√≥n gen√©rica para detectar formato de cualquier campo\n",
    "def detectar_formato_generico(valor):\n",
    "    \"\"\"Detecta el patr√≥n general de un valor\"\"\"\n",
    "    if pd.isnull(valor):\n",
    "        return 'NULL'\n",
    "    \n",
    "    valor_str = str(valor).strip()\n",
    "    \n",
    "    if valor_str == '-' or valor_str == '':\n",
    "        return 'PLACEHOLDER'\n",
    "    \n",
    "    # Crear patr√≥n simplificado\n",
    "    patron = re.sub(r'\\d', 'D', valor_str)  # D√≠gitos -> D\n",
    "    patron = re.sub(r'[a-zA-Z]', 'A', patron)  # Letras -> A\n",
    "    patron = re.sub(r'\\s+', ' ', patron)  # Normalizar espacios\n",
    "    \n",
    "    return patron[:50]  # Limitar longitud\n",
    "\n",
    "# Analizar todas las columnas de texto\n",
    "problemas_formato = {}\n",
    "\n",
    "for col in df.select_dtypes(include=\"object\").columns:\n",
    "    # Detectar tipo de columna\n",
    "    nombre_lower = col.lower()\n",
    "    \n",
    "    # Determinar funci√≥n de detecci√≥n seg√∫n nombre de columna\n",
    "    if 'fecha' in nombre_lower or 'date' in nombre_lower or '_date' in col:\n",
    "        formatos = df[col].apply(detectar_formato_fecha)\n",
    "        tipo_campo = 'FECHA'\n",
    "    elif 'hora' in nombre_lower or 'time' in nombre_lower or '_time' in col:\n",
    "        formatos = df[col].apply(detectar_formato_hora)\n",
    "        tipo_campo = 'HORA'\n",
    "    elif 'timestamp' in nombre_lower:\n",
    "        formatos = df[col].apply(detectar_formato_fecha)\n",
    "        tipo_campo = 'TIMESTAMP'\n",
    "    else:\n",
    "        formatos = df[col].apply(detectar_formato_generico)\n",
    "        tipo_campo = 'GENERICO'\n",
    "    \n",
    "    # Contar formatos √∫nicos\n",
    "    conteo_formatos = formatos.value_counts()\n",
    "    \n",
    "    # Si hay m√°s de 1 formato (excluyendo NULL y PLACEHOLDER), hay inconsistencia\n",
    "    formatos_significativos = [f for f in conteo_formatos.index \n",
    "                               if f not in ['NULL', 'PLACEHOLDER', 'NO_FECHA', 'NO_HORA', 'NO_GENERICO']]\n",
    "    \n",
    "    if len(formatos_significativos) > 1 or (len(formatos_significativos) == 1 and len(conteo_formatos) > 2):\n",
    "        problemas_formato[col] = {\n",
    "            'tipo': tipo_campo,\n",
    "            'formatos': conteo_formatos.to_dict(),\n",
    "            'num_formatos': len(conteo_formatos)\n",
    "        }\n",
    "\n",
    "# Mostrar resultados\n",
    "if problemas_formato:\n",
    "    print(f\"\\n‚ö†Ô∏è  SE DETECTARON INCONSISTENCIAS DE FORMATO EN {len(problemas_formato)} COLUMNA(S)\\n\")\n",
    "    \n",
    "    # Para cada columna con problemas\n",
    "    for col, info in problemas_formato.items():\n",
    "        print(\"=\"*80)\n",
    "        print(f\"üìä COLUMNA: {col}\")\n",
    "        print(f\"   Tipo detectado: {info['tipo']}\")\n",
    "        print(f\"   N√∫mero de formatos diferentes: {info['num_formatos']}\")\n",
    "        print(\"-\"*80)\n",
    "        \n",
    "        # Crear DataFrame de distribuci√≥n de formatos\n",
    "        formatos_df = pd.DataFrame.from_dict(info['formatos'], orient='index', columns=['Cantidad'])\n",
    "        formatos_df['Porcentaje'] = (formatos_df['Cantidad'] / len(df) * 100).round(2)\n",
    "        formatos_df = formatos_df.sort_values('Cantidad', ascending=False)\n",
    "        formatos_df.index.name = 'Formato'\n",
    "        \n",
    "        print(\"\\nDistribuci√≥n de formatos:\")\n",
    "        display(formatos_df)\n",
    "        \n",
    "        # Mostrar ejemplos de cada formato\n",
    "        print(\"\\nEjemplos de cada formato:\")\n",
    "        for formato in formatos_df.index[:10]:  # Mostrar m√°ximo 10 formatos\n",
    "            if info['tipo'] == 'FECHA':\n",
    "                mask = df[col].apply(detectar_formato_fecha) == formato\n",
    "            elif info['tipo'] in ['HORA', 'TIMESTAMP']:\n",
    "                mask = df[col].apply(detectar_formato_hora) == formato\n",
    "            else:\n",
    "                mask = df[col].apply(detectar_formato_generico) == formato\n",
    "            \n",
    "            ejemplos = df.loc[mask, col].head(3).tolist()\n",
    "            print(f\"  ‚Ä¢ {formato}: {ejemplos}\")\n",
    "        \n",
    "        # Gr√°fico de barras para esta columna\n",
    "        if len(formatos_df) <= 15:  # Solo graficar si no hay demasiados formatos\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            \n",
    "            colores = plt.cm.Set3(range(len(formatos_df)))\n",
    "            barras = plt.bar(range(len(formatos_df)), formatos_df['Cantidad'], \n",
    "                           color=colores, edgecolor='black', linewidth=1.2)\n",
    "            \n",
    "            # Agregar valores\n",
    "            for i, (barra, valor, pct) in enumerate(zip(barras, formatos_df['Cantidad'], formatos_df['Porcentaje'])):\n",
    "                plt.text(barra.get_x() + barra.get_width()/2, barra.get_height(),\n",
    "                        f'{int(valor)}\\n({pct}%)',\n",
    "                        ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "            \n",
    "            plt.xlabel('Tipo de formato', fontsize=11, fontweight='bold')\n",
    "            plt.ylabel('Cantidad de registros', fontsize=11, fontweight='bold')\n",
    "            plt.title(f'Distribuci√≥n de Formatos en columna: {col}\\n({info[\"tipo\"]})', \n",
    "                     fontsize=13, fontweight='bold', pad=15)\n",
    "            plt.xticks(range(len(formatos_df)), formatos_df.index, rotation=45, ha='right')\n",
    "            plt.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "        print(\"\\n\")\n",
    "    \n",
    "    # Resumen general\n",
    "    print(\"=\"*80)\n",
    "    print(\"RESUMEN GENERAL DE INCONSISTENCIAS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    resumen_general = pd.DataFrame([\n",
    "        {\n",
    "            'Columna': col,\n",
    "            'Tipo': info['tipo'],\n",
    "            'Formatos diferentes': info['num_formatos'],\n",
    "            'Formato principal': max(info['formatos'], key=info['formatos'].get),\n",
    "            'Registros formato principal': max(info['formatos'].values())\n",
    "        }\n",
    "        for col, info in problemas_formato.items()\n",
    "    ])\n",
    "    \n",
    "    display(resumen_general)\n",
    "    \n",
    "    # Recomendaciones\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RECOMENDACIONES\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"1. Estandarizar formatos de fecha al formato ISO 8601 (YYYY-MM-DD)\")\n",
    "    print(\"2. Usar pd.to_datetime() con par√°metros para manejar formatos mixtos:\")\n",
    "    print(\"   df['columna'] = pd.to_datetime(df['columna'], format='%d/%m/%y', errors='coerce')\")\n",
    "    print(\"3. Para fechas con m√∫ltiples formatos, usar infer_datetime_format=True:\")\n",
    "    print(\"   df['columna'] = pd.to_datetime(df['columna'], infer_datetime_format=True, errors='coerce')\")\n",
    "    print(\"4. Identificar y corregir valores '-' o placeholders antes de conversi√≥n\")\n",
    "    print(\"5. Validar que todas las fechas convertidas sean coherentes\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚úÖ NO SE DETECTARON INCONSISTENCIAS DE FORMATO\")\n",
    "    print(\"\\nTodas las columnas tienen formatos consistentes.\")\n",
    "    print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee69dc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Errores categ√≥ricos ---\n",
    "print(\"\\nValores √∫nicos por columna categ√≥rica:\")\n",
    "for col in df.select_dtypes(include=\"object\").columns:\n",
    "    print(f\"{col}: {df[col].unique()[:10]} ...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jefooi7zla9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# --- Detecci√≥n de espacios adicionales en categor√≠as ---\n",
    "# ============================================\n",
    "\n",
    "import re\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AN√ÅLISIS DE ESPACIOS ADICIONALES EN CATEGOR√çAS\")\n",
    "print(\"=\"*80)\n",
    "print(\"(Detectando espacios al inicio, final o m√∫ltiples que causan inconsistencias)\\n\")\n",
    "\n",
    "# Funci√≥n para analizar espacios en valores\n",
    "def analizar_espacios(valor):\n",
    "    \"\"\"Analiza si un valor tiene espacios problem√°ticos\"\"\"\n",
    "    if pd.isnull(valor):\n",
    "        return None\n",
    "    \n",
    "    valor_str = str(valor)\n",
    "    problemas = {\n",
    "        'leading': len(valor_str) - len(valor_str.lstrip()),\n",
    "        'trailing': len(valor_str) - len(valor_str.rstrip()),\n",
    "        'multiple': len(re.findall(r'\\s{2,}', valor_str)),\n",
    "        'valor_limpio': valor_str.strip(),\n",
    "        'longitud_original': len(valor_str),\n",
    "        'longitud_limpia': len(valor_str.strip())\n",
    "    }\n",
    "    return problemas\n",
    "\n",
    "# Analizar cada columna categ√≥rica\n",
    "problemas_espacios = {}\n",
    "\n",
    "for col in df.select_dtypes(include=\"object\").columns:\n",
    "    # Analizar espacios en cada valor\n",
    "    analisis = df[col].apply(analizar_espacios)\n",
    "    \n",
    "    # Filtrar valores con problemas (tienen espacios adicionales)\n",
    "    valores_con_problemas = df[col][\n",
    "        analisis.apply(lambda x: x is not None and \n",
    "                      (x['leading'] > 0 or x['trailing'] > 0 or x['multiple'] > 0))\n",
    "    ]\n",
    "    \n",
    "    if len(valores_con_problemas) > 0:\n",
    "        # Agrupar valores por su versi√≥n limpia\n",
    "        valores_limpios = valores_con_problemas.apply(lambda x: str(x).strip())\n",
    "        \n",
    "        # Encontrar casos donde el mismo valor limpio tiene m√∫ltiples representaciones\n",
    "        grupos_duplicados = {}\n",
    "        for valor_limpio in valores_limpios.unique():\n",
    "            # Encontrar todas las variantes con espacios de este valor\n",
    "            variantes = valores_con_problemas[valores_limpios == valor_limpio].unique()\n",
    "            if len(variantes) > 1 or any(v != valor_limpio for v in variantes):\n",
    "                grupos_duplicados[valor_limpio] = {\n",
    "                    'variantes': list(variantes),\n",
    "                    'longitudes': [len(v) for v in variantes],\n",
    "                    'total_registros': len(valores_con_problemas[valores_limpios == valor_limpio])\n",
    "                }\n",
    "        \n",
    "        if grupos_duplicados or len(valores_con_problemas) > 0:\n",
    "            problemas_espacios[col] = {\n",
    "                'total_afectados': len(valores_con_problemas),\n",
    "                'porcentaje': (len(valores_con_problemas) / len(df)) * 100,\n",
    "                'grupos_duplicados': grupos_duplicados,\n",
    "                'leading_count': sum(analisis.apply(lambda x: x['leading'] if x else 0) > 0),\n",
    "                'trailing_count': sum(analisis.apply(lambda x: x['trailing'] if x else 0) > 0),\n",
    "                'multiple_count': sum(analisis.apply(lambda x: x['multiple'] if x else 0) > 0)\n",
    "            }\n",
    "\n",
    "# Mostrar resultados\n",
    "if problemas_espacios:\n",
    "    print(f\"‚ö†Ô∏è  SE DETECTARON PROBLEMAS DE ESPACIOS EN {len(problemas_espacios)} COLUMNA(S)\\n\")\n",
    "    \n",
    "    # Resumen general\n",
    "    resumen_data = []\n",
    "    for col, info in problemas_espacios.items():\n",
    "        resumen_data.append({\n",
    "            'Columna': col,\n",
    "            'Registros afectados': info['total_afectados'],\n",
    "            'Porcentaje (%)': round(info['porcentaje'], 2),\n",
    "            'Espacios al inicio': info['leading_count'],\n",
    "            'Espacios al final': info['trailing_count'],\n",
    "            'Espacios m√∫ltiples': info['multiple_count'],\n",
    "            'Valores duplicados': len(info['grupos_duplicados'])\n",
    "        })\n",
    "    \n",
    "    resumen_df = pd.DataFrame(resumen_data)\n",
    "    resumen_df = resumen_df.sort_values('Registros afectados', ascending=False)\n",
    "    \n",
    "    print(\"RESUMEN GENERAL:\")\n",
    "    print(\"-\"*80)\n",
    "    display(resumen_df)\n",
    "    \n",
    "    # Gr√°fico de resumen\n",
    "    if len(problemas_espacios) > 0:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        \n",
    "        # Gr√°fico 1: Registros afectados por columna\n",
    "        cols = resumen_df['Columna'].tolist()\n",
    "        valores = resumen_df['Registros afectados'].tolist()\n",
    "        colores = plt.cm.Reds(np.linspace(0.4, 0.9, len(cols)))\n",
    "        \n",
    "        barras = ax1.barh(cols, valores, color=colores, edgecolor='black', linewidth=1.2)\n",
    "        for barra, valor, pct in zip(barras, valores, resumen_df['Porcentaje (%)']):\n",
    "            ax1.text(barra.get_width(), barra.get_y() + barra.get_height()/2,\n",
    "                    f' {int(valor)} ({pct}%)',\n",
    "                    va='center', fontweight='bold', fontsize=9)\n",
    "        \n",
    "        ax1.set_xlabel('N√∫mero de registros con espacios adicionales', fontsize=11, fontweight='bold')\n",
    "        ax1.set_ylabel('Columna', fontsize=11, fontweight='bold')\n",
    "        ax1.set_title('Registros Afectados por Espacios Adicionales', fontsize=12, fontweight='bold')\n",
    "        ax1.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "        \n",
    "        # Gr√°fico 2: Tipo de problema\n",
    "        tipos_problemas = resumen_df[['Espacios al inicio', 'Espacios al final', 'Espacios m√∫ltiples']].sum()\n",
    "        colores_tipos = ['#ff6b6b', '#feca57', '#48dbfb']\n",
    "        \n",
    "        barras2 = ax2.bar(tipos_problemas.index, tipos_problemas.values, \n",
    "                         color=colores_tipos, edgecolor='black', linewidth=1.2)\n",
    "        for barra, valor in zip(barras2, tipos_problemas.values):\n",
    "            ax2.text(barra.get_x() + barra.get_width()/2, barra.get_height(),\n",
    "                    f'{int(valor)}',\n",
    "                    ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
    "        \n",
    "        ax2.set_ylabel('Cantidad de registros', fontsize=11, fontweight='bold')\n",
    "        ax2.set_title('Distribuci√≥n por Tipo de Problema', fontsize=12, fontweight='bold')\n",
    "        ax2.set_xticklabels(tipos_problemas.index, rotation=15, ha='right')\n",
    "        ax2.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Detalles por columna\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"DETALLES POR COLUMNA\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for col, info in problemas_espacios.items():\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"üìã COLUMNA: {col}\")\n",
    "        print(f\"   Total registros afectados: {info['total_afectados']} ({info['porcentaje']:.2f}%)\")\n",
    "        print(f\"   Espacios al inicio: {info['leading_count']}\")\n",
    "        print(f\"   Espacios al final: {info['trailing_count']}\")\n",
    "        print(f\"   Espacios m√∫ltiples internos: {info['multiple_count']}\")\n",
    "        print(\"-\"*80)\n",
    "        \n",
    "        # Mostrar grupos duplicados (mismo valor con diferentes espacios)\n",
    "        if info['grupos_duplicados']:\n",
    "            print(f\"\\n   ‚ö†Ô∏è  VALORES DUPLICADOS POR ESPACIOS ({len(info['grupos_duplicados'])} casos):\\n\")\n",
    "            \n",
    "            # Limitar a mostrar los primeros 10 grupos\n",
    "            for i, (valor_limpio, detalle) in enumerate(list(info['grupos_duplicados'].items())[:10], 1):\n",
    "                print(f\"   {i}. Valor base: '{valor_limpio}' (longitud: {len(valor_limpio)})\")\n",
    "                print(f\"      Afecta a {detalle['total_registros']} registros\")\n",
    "                print(f\"      Variantes encontradas ({len(detalle['variantes'])}):\")\n",
    "                \n",
    "                for j, (variante, longitud) in enumerate(zip(detalle['variantes'], detalle['longitudes']), 1):\n",
    "                    # Representaci√≥n visual de los espacios\n",
    "                    repr_variante = repr(variante)\n",
    "                    espacios_inicio = len(variante) - len(variante.lstrip())\n",
    "                    espacios_final = len(variante) - len(variante.rstrip())\n",
    "                    \n",
    "                    indicador = \"\"\n",
    "                    if espacios_inicio > 0:\n",
    "                        indicador += f\"‚Üê{espacios_inicio} espacio(s) al inicio \"\n",
    "                    if espacios_final > 0:\n",
    "                        indicador += f\"‚Üí{espacios_final} espacio(s) al final \"\n",
    "                    \n",
    "                    print(f\"         {j}. {repr_variante} [Long: {longitud}] {indicador}\")\n",
    "                print()\n",
    "            \n",
    "            if len(info['grupos_duplicados']) > 10:\n",
    "                print(f\"   ... y {len(info['grupos_duplicados']) - 10} grupos m√°s\\n\")\n",
    "        \n",
    "        # Mostrar ejemplos de registros afectados\n",
    "        print(\"   Ejemplos de valores con espacios adicionales:\")\n",
    "        valores_ejemplo = df[col][\n",
    "            df[col].apply(lambda x: x is not None and \n",
    "                         (len(str(x)) != len(str(x).strip()) if x is not None else False))\n",
    "        ].head(5)\n",
    "        \n",
    "        for idx, valor in enumerate(valores_ejemplo, 1):\n",
    "            print(f\"      {idx}. {repr(valor)} ‚Üí limpio: {repr(str(valor).strip())}\")\n",
    "        print()\n",
    "    \n",
    "    # Recomendaciones\n",
    "    print(\"=\"*80)\n",
    "    print(\"RECOMENDACIONES\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"1. Limpiar espacios usando el m√©todo .strip():\")\n",
    "    print(\"   df['columna'] = df['columna'].str.strip()\")\n",
    "    print(\"\\n2. Para m√∫ltiples espacios internos, usar regex:\")\n",
    "    print(\"   df['columna'] = df['columna'].str.replace(r'\\\\s+', ' ', regex=True)\")\n",
    "    print(\"\\n3. Aplicar limpieza a todas las columnas de texto:\")\n",
    "    print(\"   for col in df.select_dtypes(include='object').columns:\")\n",
    "    print(\"       df[col] = df[col].str.strip()\")\n",
    "    print(\"\\n4. Verificar despu√©s de limpiar que no se crearon duplicados\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "else:\n",
    "    print(\"‚úÖ NO SE DETECTARON PROBLEMAS DE ESPACIOS ADICIONALES\")\n",
    "    print(\"\\nTodas las columnas categ√≥ricas tienen valores sin espacios problem√°ticos.\")\n",
    "    print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2373391",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "# --- Outliers ---\n",
    "num_cols = df.select_dtypes(include=np.number).columns\n",
    "z_scores = pd.DataFrame(zscore(df[num_cols], nan_policy='omit'), columns=num_cols)\n",
    "outliers_mask = (np.abs(z_scores) > 3)\n",
    "outliers_count = outliers_mask.sum()\n",
    "print(\"\\nDetecci√≥n de outliers (z-score > 3):\")\n",
    "print(outliers_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12212c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Campos redundantes ---\n",
    "low_var_cols = [col for col in df.columns if df[col].nunique() <= 1]\n",
    "print(\"\\nColumnas con baja varianza (posibles redundantes):\")\n",
    "print(low_var_cols)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46b0ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# --- Codificaci√≥n incorrecta ---\n",
    "# ============================================\n",
    "\n",
    "import re\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AN√ÅLISIS DE PROBLEMAS DE CODIFICACI√ìN (ENCODING)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Funci√≥n para detectar problemas de encoding\n",
    "def detectar_problemas_encoding(texto):\n",
    "    \"\"\"Detecta varios tipos de problemas de encoding en un texto\"\"\"\n",
    "    if pd.isnull(texto):\n",
    "        return []\n",
    "    \n",
    "    texto_str = str(texto)\n",
    "    problemas = []\n",
    "    \n",
    "    # 1. Detectar caracter de reemplazo (ÔøΩ)\n",
    "    if 'ÔøΩ' in texto_str:\n",
    "        problemas.append('replacement_char')\n",
    "    \n",
    "    # 2. Detectar secuencias UTF-8 mal decodificadas (como √É¬©, √É¬±, etc.)\n",
    "    if re.search(r'[√É√Ç][^a-zA-Z0-9\\s]', texto_str):\n",
    "        problemas.append('utf8_malformed')\n",
    "    \n",
    "    # 3. Detectar caracteres de control (no imprimibles)\n",
    "    if re.search(r'[\\x00-\\x08\\x0b-\\x0c\\x0e-\\x1f\\x7f-\\x9f]', texto_str):\n",
    "        problemas.append('control_chars')\n",
    "    \n",
    "    # 4. Detectar mezcla sospechosa de caracteres latinos y otros\n",
    "    if re.search(r'[^\\x00-\\x7F\\u00C0-\\u017F\\u0020-\\u007E\\u00A0-\\u00FF]', texto_str):\n",
    "        problemas.append('mixed_encoding')\n",
    "    \n",
    "    # 5. Detectar espacios duplicados o extra√±os\n",
    "    if re.search(r'\\s{3,}|[\\u00A0\\u2000-\\u200B]', texto_str):\n",
    "        problemas.append('weird_spaces')\n",
    "    \n",
    "    return problemas\n",
    "\n",
    "# Analizar cada columna de texto\n",
    "resultados_encoding = {}\n",
    "ejemplos_problemas = {}\n",
    "\n",
    "for col in df.select_dtypes(include=\"object\").columns:\n",
    "    # Detectar problemas en cada valor\n",
    "    problemas_por_fila = df[col].apply(detectar_problemas_encoding)\n",
    "    \n",
    "    # Contar filas con problemas\n",
    "    filas_con_problemas = problemas_por_fila.apply(lambda x: len(x) > 0).sum()\n",
    "    \n",
    "    if filas_con_problemas > 0:\n",
    "        # Guardar estad√≠sticas\n",
    "        resultados_encoding[col] = {\n",
    "            'total_problemas': filas_con_problemas,\n",
    "            'porcentaje': (filas_con_problemas / len(df)) * 100\n",
    "        }\n",
    "        \n",
    "        # Guardar ejemplos de valores con problemas\n",
    "        indices_problemas = problemas_por_fila[problemas_por_fila.apply(lambda x: len(x) > 0)].index[:5]\n",
    "        ejemplos_problemas[col] = df.loc[indices_problemas, col].tolist()\n",
    "\n",
    "# Mostrar resultados\n",
    "if resultados_encoding:\n",
    "    print(f\"\\n‚ö†Ô∏è  SE DETECTARON PROBLEMAS DE ENCODING EN {len(resultados_encoding)} COLUMNA(S)\\n\")\n",
    "    \n",
    "    # Crear DataFrame resumen\n",
    "    resumen_df = pd.DataFrame.from_dict(resultados_encoding, orient='index')\n",
    "    resumen_df = resumen_df.sort_values('total_problemas', ascending=False)\n",
    "    resumen_df['porcentaje'] = resumen_df['porcentaje'].round(2)\n",
    "    resumen_df.columns = ['Registros afectados', 'Porcentaje (%)']\n",
    "    \n",
    "    print(\"RESUMEN DE PROBLEMAS POR COLUMNA:\")\n",
    "    print(\"-\" * 80)\n",
    "    display(resumen_df)\n",
    "    \n",
    "    # Gr√°fico de barras\n",
    "    if len(resultados_encoding) > 0:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        cols_plot = resumen_df.index.tolist()\n",
    "        valores_plot = resumen_df['Registros afectados'].tolist()\n",
    "        \n",
    "        colores = ['#ff6b6b' if v > len(df)*0.1 else '#feca57' if v > len(df)*0.01 else '#48dbfb' \n",
    "                   for v in valores_plot]\n",
    "        \n",
    "        barras = plt.barh(cols_plot, valores_plot, color=colores, edgecolor='black', linewidth=1.2)\n",
    "        \n",
    "        # Agregar valores en las barras\n",
    "        for i, (barra, valor) in enumerate(zip(barras, valores_plot)):\n",
    "            porcentaje = (valor / len(df)) * 100\n",
    "            plt.text(barra.get_width(), barra.get_y() + barra.get_height()/2,\n",
    "                    f' {int(valor)} ({porcentaje:.1f}%)',\n",
    "                    va='center', fontweight='bold', fontsize=10)\n",
    "        \n",
    "        plt.xlabel('N√∫mero de registros con problemas de encoding', fontsize=11, fontweight='bold')\n",
    "        plt.ylabel('Columna', fontsize=11, fontweight='bold')\n",
    "        plt.title('Problemas de Encoding por Columna\\n(Rojo: >10% | Amarillo: >1% | Azul: <1%)', \n",
    "                 fontsize=13, fontweight='bold', pad=15)\n",
    "        plt.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Mostrar ejemplos detallados\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"EJEMPLOS DE VALORES CON PROBLEMAS DE ENCODING\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for col, ejemplos in ejemplos_problemas.items():\n",
    "        print(f\"\\nüìã Columna: {col}\")\n",
    "        print(f\"   Registros afectados: {resultados_encoding[col]['total_problemas']} ({resultados_encoding[col]['porcentaje']:.2f}%)\")\n",
    "        print(f\"   Ejemplos de valores con problemas:\")\n",
    "        for i, ejemplo in enumerate(ejemplos, 1):\n",
    "            # Mostrar representaci√≥n del valor\n",
    "            repr_valor = repr(ejemplo)\n",
    "            if len(repr_valor) > 80:\n",
    "                repr_valor = repr_valor[:77] + \"...\"\n",
    "            print(f\"      {i}. {repr_valor}\")\n",
    "        print(\"-\" * 80)\n",
    "    \n",
    "    # Recomendaciones\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RECOMENDACIONES\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"1. Verificar el encoding del archivo fuente (UTF-8, ISO-8859-1, etc.)\")\n",
    "    print(\"2. Re-cargar el CSV especificando el encoding correcto:\")\n",
    "    print(\"   Ejemplo: pd.read_csv('archivo.csv', encoding='latin-1')\")\n",
    "    print(\"3. Considerar usar ftfy (fix text for you) para corregir autom√°ticamente:\")\n",
    "    print(\"   pip install ftfy\")\n",
    "    print(\"   from ftfy import fix_text\")\n",
    "    print(\"   df[col] = df[col].apply(lambda x: fix_text(x) if pd.notnull(x) else x)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚úÖ NO SE DETECTARON PROBLEMAS DE ENCODING\")\n",
    "    print(\"\\nTodas las columnas de texto tienen codificaci√≥n correcta.\")\n",
    "    print(\"\\nSe verificaron los siguientes problemas comunes:\")\n",
    "    print(\"  ‚Ä¢ Caracteres de reemplazo (ÔøΩ)\")\n",
    "    print(\"  ‚Ä¢ Secuencias UTF-8 mal decodificadas\")\n",
    "    print(\"  ‚Ä¢ Caracteres de control no imprimibles\")\n",
    "    print(\"  ‚Ä¢ Mezcla de encodings diferentes\")\n",
    "    print(\"  ‚Ä¢ Espacios extra√±os o duplicados\")\n",
    "    print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2d17b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 4. Visualizaciones r√°pidas en la celda 13 \n",
    "# ============================================\n",
    "\n",
    "# Mapa de valores nulos\n",
    "sns.heatmap(df.isnull(), cbar=False)\n",
    "plt.title(\"Mapa de valores nulos\")\n",
    "plt.show()\n",
    "\n",
    "# Boxplot solo para columnas num√©ricas con datos suficientes\n",
    "for col in num_cols:\n",
    "    if df[col].dropna().nunique() > 1:  # al menos dos valores distintos\n",
    "        plt.figure(figsize=(6,3))\n",
    "        sns.boxplot(x=df[col])\n",
    "        plt.title(f\"Outliers en {col}\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Columna '{col}' omitida: no tiene suficientes datos num√©ricos v√°lidos para graficar.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfe359c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================\n",
    "# 5. Reporte final\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\\n--- REPORTE DE PROBLEMAS DETECTADOS ---\")\n",
    "print(\"1. Valores nulos detectados en:\", df.columns[df.isnull().any()].tolist())\n",
    "print(\"2. Filas duplicadas:\", df.duplicated().sum())\n",
    "print(\"3. Columnas con problemas de formato revisadas manualmente.\")\n",
    "print(\"4. Columnas con outliers en columnas num√©ricas:\", outliers_count[outliers_count > 0].index.tolist())\n",
    "print(\"5. Columnas redundantes:\", low_var_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0f358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "from difflib import get_close_matches\n",
    "\n",
    "# ============================================\n",
    "# 6. Validaci√≥n de caracteres especiales y errores de escritura\n",
    "# ============================================\n",
    "\n",
    "# --- 6.1 Detectar caracteres especiales ---\n",
    "print(\"\\nCaracteres especiales detectados en columnas de texto:\")\n",
    "for col in df.select_dtypes(include=\"object\").columns:\n",
    "    especiales = df[col].dropna().apply(lambda x: re.findall(r\"[^a-zA-Z0-9\\s√°√©√≠√≥√∫√Å√â√ç√ì√ö√±√ë]\", str(x)))\n",
    "    especiales = [c for sub in especiales for c in sub]\n",
    "    if especiales:\n",
    "        print(f\"Columna {col}: {set(especiales)}\")\n",
    "\n",
    "# --- 6.2 Normalizaci√≥n de texto ---\n",
    "def normalizar_texto(texto):\n",
    "    if pd.isnull(texto):\n",
    "        return texto\n",
    "    # Pasar a min√∫sculas\n",
    "    texto = texto.lower().strip()\n",
    "    # Quitar acentos\n",
    "    texto = ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', texto)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "    return texto\n",
    "\n",
    "for col in df.select_dtypes(include=\"object\").columns:\n",
    "    df[col] = df[col].apply(normalizar_texto)\n",
    "\n",
    "# --- 6.3 Detectar variantes de categor√≠as ---\n",
    "print(\"\\nPosibles errores de categorizaci√≥n (formas diferentes de lo mismo):\")\n",
    "for col in df.select_dtypes(include=\"object\").columns:\n",
    "    valores = df[col].dropna().unique()\n",
    "    if len(valores) < 50:  # solo columnas con pocas categor√≠as\n",
    "        print(f\"\\nColumna {col}:\")\n",
    "        for v in valores:\n",
    "            similares = get_close_matches(v, valores, cutoff=0.8)\n",
    "            if len(similares) > 1:\n",
    "                print(f\"  '{v}' ~ {similares}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f54485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores √∫nicos con su frecuencia en formato DataFrame\n",
    "# df_unicos_conteo = df[\"AddressType\"].value_counts().reset_index()\n",
    "# df_unicos_conteo.columns = [\"AddressType\", \"conteo\"]\n",
    "# display(df_unicos_conteo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3vftb17nryj",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# --- Detecci√≥n de caracteres especiales at√≠picos ---\n",
    "# ============================================\n",
    "\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AN√ÅLISIS DE CARACTERES ESPECIALES AT√çPICOS\")\n",
    "print(\"=\"*80)\n",
    "print(\"(Detectando caracteres no est√°ndar que pueden causar problemas)\\n\")\n",
    "\n",
    "# Definir caracteres permitidos/comunes\n",
    "# Ajustar seg√∫n necesidades del dataset\n",
    "CARACTERES_COMUNES = set(\n",
    "    'abcdefghijklmnopqrstuvwxyz'\n",
    "    'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "    '√°√©√≠√≥√∫√Å√â√ç√ì√ö√±√ë√º√ú'  # Acentos espa√±oles\n",
    "    '0123456789'\n",
    "    ' .,;:/-_()[]{}@#$%&*+=<>?!\"\\'\\n\\t'  # Puntuaci√≥n com√∫n\n",
    ")\n",
    "\n",
    "def detectar_caracteres_atipicos(valor):\n",
    "    \"\"\"Detecta caracteres at√≠picos en un valor\"\"\"\n",
    "    if pd.isnull(valor):\n",
    "        return None\n",
    "    \n",
    "    valor_str = str(valor)\n",
    "    caracteres_atipicos = []\n",
    "    \n",
    "    for char in valor_str:\n",
    "        if char not in CARACTERES_COMUNES:\n",
    "            # Obtener informaci√≥n del caracter\n",
    "            try:\n",
    "                nombre_unicode = unicodedata.name(char, 'DESCONOCIDO')\n",
    "                categoria = unicodedata.category(char)\n",
    "            except:\n",
    "                nombre_unicode = 'ERROR'\n",
    "                categoria = 'UNKNOWN'\n",
    "            \n",
    "            caracteres_atipicos.append({\n",
    "                'char': char,\n",
    "                'codigo': ord(char),\n",
    "                'hex': hex(ord(char)),\n",
    "                'nombre': nombre_unicode,\n",
    "                'categoria': categoria\n",
    "            })\n",
    "    \n",
    "    return caracteres_atipicos if caracteres_atipicos else None\n",
    "\n",
    "# Analizar todas las columnas de texto\n",
    "problemas_caracteres = {}\n",
    "\n",
    "for col in df.select_dtypes(include=\"object\").columns:\n",
    "    # Detectar caracteres at√≠picos en cada valor\n",
    "    caracteres_por_valor = df[col].apply(detectar_caracteres_atipicos)\n",
    "    \n",
    "    # Filtrar valores con caracteres at√≠picos\n",
    "    valores_con_atipicos = caracteres_por_valor[caracteres_por_valor.notna()]\n",
    "    \n",
    "    if len(valores_con_atipicos) > 0:\n",
    "        # Recopilar todos los caracteres √∫nicos encontrados\n",
    "        chars_unicos = {}\n",
    "        ejemplos_valores = []\n",
    "        \n",
    "        for idx, lista_chars in valores_con_atipicos.items():\n",
    "            if lista_chars:\n",
    "                # Guardar ejemplo del valor completo\n",
    "                if len(ejemplos_valores) < 10:\n",
    "                    ejemplos_valores.append({\n",
    "                        'valor': df.loc[idx, col],\n",
    "                        'caracteres': [c['char'] for c in lista_chars]\n",
    "                    })\n",
    "                \n",
    "                # Agrupar caracteres √∫nicos\n",
    "                for char_info in lista_chars:\n",
    "                    char = char_info['char']\n",
    "                    if char not in chars_unicos:\n",
    "                        chars_unicos[char] = {\n",
    "                            'info': char_info,\n",
    "                            'count': 0,\n",
    "                            'ejemplos': []\n",
    "                        }\n",
    "                    chars_unicos[char]['count'] += 1\n",
    "                    if len(chars_unicos[char]['ejemplos']) < 3:\n",
    "                        chars_unicos[char]['ejemplos'].append(df.loc[idx, col])\n",
    "        \n",
    "        problemas_caracteres[col] = {\n",
    "            'total_valores_afectados': len(valores_con_atipicos),\n",
    "            'porcentaje': (len(valores_con_atipicos) / len(df)) * 100,\n",
    "            'caracteres_unicos': chars_unicos,\n",
    "            'ejemplos_valores': ejemplos_valores\n",
    "        }\n",
    "\n",
    "# Mostrar resultados\n",
    "if problemas_caracteres:\n",
    "    print(f\"‚ö†Ô∏è  SE DETECTARON CARACTERES AT√çPICOS EN {len(problemas_caracteres)} COLUMNA(S)\\n\")\n",
    "    \n",
    "    # Resumen general\n",
    "    print(\"=\"*80)\n",
    "    print(\"RESUMEN GENERAL\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    resumen_data = []\n",
    "    for col, info in problemas_caracteres.items():\n",
    "        resumen_data.append({\n",
    "            'Columna': col,\n",
    "            'Valores afectados': info['total_valores_afectados'],\n",
    "            'Porcentaje (%)': round(info['porcentaje'], 2),\n",
    "            'Caracteres √∫nicos': len(info['caracteres_unicos'])\n",
    "        })\n",
    "    \n",
    "    resumen_df = pd.DataFrame(resumen_data)\n",
    "    resumen_df = resumen_df.sort_values('Valores afectados', ascending=False)\n",
    "    display(resumen_df)\n",
    "    \n",
    "    # Gr√°fico de resumen\n",
    "    if len(problemas_caracteres) > 0:\n",
    "        fig, ax = plt.subplots(figsize=(14, 6))\n",
    "        \n",
    "        cols = resumen_df['Columna'].tolist()\n",
    "        valores = resumen_df['Valores afectados'].tolist()\n",
    "        colores = plt.cm.Oranges(np.linspace(0.4, 0.9, len(cols)))\n",
    "        \n",
    "        barras = ax.barh(cols, valores, color=colores, edgecolor='black', linewidth=1.2)\n",
    "        \n",
    "        for barra, valor, pct, chars in zip(barras, valores, resumen_df['Porcentaje (%)'], \n",
    "                                            resumen_df['Caracteres √∫nicos']):\n",
    "            ax.text(barra.get_width(), barra.get_y() + barra.get_height()/2,\n",
    "                    f' {int(valor)} valores ({pct}%) | {chars} chars √∫nicos',\n",
    "                    va='center', fontweight='bold', fontsize=9)\n",
    "        \n",
    "        ax.set_xlabel('Valores con caracteres at√≠picos', fontsize=11, fontweight='bold')\n",
    "        ax.set_ylabel('Columna', fontsize=11, fontweight='bold')\n",
    "        ax.set_title('Detecci√≥n de Caracteres Especiales At√≠picos por Columna', \n",
    "                     fontsize=13, fontweight='bold', pad=15)\n",
    "        ax.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Detalles por columna\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"DETALLES POR COLUMNA\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for col, info in problemas_caracteres.items():\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"üìã COLUMNA: {col}\")\n",
    "        print(f\"   Valores afectados: {info['total_valores_afectados']} ({info['porcentaje']:.2f}%)\")\n",
    "        print(f\"   Caracteres √∫nicos at√≠picos encontrados: {len(info['caracteres_unicos'])}\")\n",
    "        print(\"-\"*80)\n",
    "        \n",
    "        # Tabla de caracteres √∫nicos\n",
    "        print(\"\\n   CARACTERES AT√çPICOS DETECTADOS:\\n\")\n",
    "        \n",
    "        chars_tabla = []\n",
    "        for char, data in sorted(info['caracteres_unicos'].items(), \n",
    "                                key=lambda x: x[1]['count'], reverse=True):\n",
    "            char_info = data['info']\n",
    "            chars_tabla.append({\n",
    "                'Caracter': f\"'{char}'\" if char.isprintable() else '[No visible]',\n",
    "                'C√≥digo': f\"U+{char_info['hex'][2:].upper().zfill(4)}\",\n",
    "                'Decimal': char_info['codigo'],\n",
    "                'Nombre Unicode': char_info['nombre'][:40],\n",
    "                'Categor√≠a': char_info['categoria'],\n",
    "                'Ocurrencias': data['count']\n",
    "            })\n",
    "        \n",
    "        chars_df = pd.DataFrame(chars_tabla)\n",
    "        display(chars_df.head(20))  # Mostrar hasta 20 caracteres\n",
    "        \n",
    "        if len(chars_tabla) > 20:\n",
    "            print(f\"\\n   ... y {len(chars_tabla) - 20} caracteres m√°s\\n\")\n",
    "        \n",
    "        # Ejemplos de valores afectados\n",
    "        print(\"\\n   EJEMPLOS DE VALORES CON CARACTERES AT√çPICOS:\\n\")\n",
    "        for i, ejemplo in enumerate(info['ejemplos_valores'][:5], 1):\n",
    "            valor = ejemplo['valor']\n",
    "            chars = ejemplo['caracteres']\n",
    "            \n",
    "            # Resaltar caracteres at√≠picos en el valor\n",
    "            valor_repr = repr(valor)\n",
    "            if len(valor_repr) > 100:\n",
    "                valor_repr = valor_repr[:97] + \"...'\"\n",
    "            \n",
    "            print(f\"   {i}. {valor_repr}\")\n",
    "            print(f\"      ‚Üí Caracteres at√≠picos: {chars}\")\n",
    "            print(f\"      ‚Üí C√≥digos Unicode: {[f'U+{hex(ord(c))[2:].upper().zfill(4)}' for c in chars]}\")\n",
    "            print()\n",
    "        \n",
    "        print(\"-\"*80)\n",
    "    \n",
    "    # Categor√≠as de caracteres m√°s comunes\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"AN√ÅLISIS DE CATEGOR√çAS UNICODE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    todas_categorias = {}\n",
    "    for col, info in problemas_caracteres.items():\n",
    "        for char_data in info['caracteres_unicos'].values():\n",
    "            cat = char_data['info']['categoria']\n",
    "            if cat not in todas_categorias:\n",
    "                todas_categorias[cat] = {'count': 0, 'descripcion': ''}\n",
    "            todas_categorias[cat]['count'] += char_data['count']\n",
    "    \n",
    "    # Descripciones de categor√≠as comunes\n",
    "    descripciones_cat = {\n",
    "        'Cc': 'Caracteres de control',\n",
    "        'Cf': 'Caracteres de formato',\n",
    "        'Cn': 'No asignados',\n",
    "        'Co': 'Uso privado',\n",
    "        'Cs': 'Sustitutos',\n",
    "        'Ll': 'Letra min√∫scula',\n",
    "        'Lm': 'Letra modificadora',\n",
    "        'Lo': 'Otra letra',\n",
    "        'Lt': 'Letra t√≠tulo',\n",
    "        'Lu': 'Letra may√∫scula',\n",
    "        'Mc': 'Marca de espaciado',\n",
    "        'Me': 'Marca adjunta',\n",
    "        'Mn': 'Marca sin espaciado',\n",
    "        'Nd': 'N√∫mero decimal',\n",
    "        'Nl': 'N√∫mero letra',\n",
    "        'No': 'Otro n√∫mero',\n",
    "        'Pc': 'Puntuaci√≥n conectora',\n",
    "        'Pd': 'Puntuaci√≥n gui√≥n',\n",
    "        'Pe': 'Puntuaci√≥n cierre',\n",
    "        'Pf': 'Puntuaci√≥n final',\n",
    "        'Pi': 'Puntuaci√≥n inicial',\n",
    "        'Po': 'Otra puntuaci√≥n',\n",
    "        'Ps': 'Puntuaci√≥n apertura',\n",
    "        'Sc': 'S√≠mbolo moneda',\n",
    "        'Sk': 'S√≠mbolo modificador',\n",
    "        'Sm': 'S√≠mbolo matem√°tico',\n",
    "        'So': 'Otro s√≠mbolo',\n",
    "        'Zl': 'Separador l√≠nea',\n",
    "        'Zp': 'Separador p√°rrafo',\n",
    "        'Zs': 'Separador espacio'\n",
    "    }\n",
    "    \n",
    "    print(\"\\nDistribuci√≥n por categor√≠a Unicode:\")\n",
    "    for cat, data in sorted(todas_categorias.items(), key=lambda x: x[1]['count'], reverse=True):\n",
    "        desc = descripciones_cat.get(cat, 'Desconocido')\n",
    "        print(f\"  ‚Ä¢ {cat} ({desc}): {data['count']} ocurrencias\")\n",
    "    \n",
    "    # Recomendaciones\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RECOMENDACIONES\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"1. Revisar si los caracteres at√≠picos son leg√≠timos o errores de encoding\")\n",
    "    print(\"\\n2. Para eliminar caracteres no ASCII:\")\n",
    "    print(\"   df['columna'] = df['columna'].str.encode('ascii', 'ignore').str.decode('ascii')\")\n",
    "    print(\"\\n3. Para normalizar caracteres Unicode (quitar acentos):\")\n",
    "    print(\"   import unicodedata\")\n",
    "    print(\"   def normalizar(texto):\")\n",
    "    print(\"       return ''.join(c for c in unicodedata.normalize('NFD', texto)\")\n",
    "    print(\"                      if unicodedata.category(c) != 'Mn')\")\n",
    "    print(\"\\n4. Para reemplazar caracteres espec√≠ficos:\")\n",
    "    print(\"   df['columna'] = df['columna'].str.replace('[caracter]', '', regex=False)\")\n",
    "    print(\"\\n5. Verificar el encoding del archivo original (UTF-8, Latin-1, etc.)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "else:\n",
    "    print(\"‚úÖ NO SE DETECTARON CARACTERES AT√çPICOS\")\n",
    "    print(\"\\nTodas las columnas contienen solo caracteres est√°ndar.\")\n",
    "    print(\"\\nCaracteres considerados est√°ndar:\")\n",
    "    print(\"  ‚Ä¢ Letras: a-z, A-Z\")\n",
    "    print(\"  ‚Ä¢ Acentos espa√±oles: √°, √©, √≠, √≥, √∫, √±, √º\")\n",
    "    print(\"  ‚Ä¢ N√∫meros: 0-9\")\n",
    "    print(\"  ‚Ä¢ Puntuaci√≥n com√∫n: . , ; : / - _ ( ) [ ] { } @ # $ % & * + = < > ? ! \\\" '\")\n",
    "    print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbc0b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar filas donde la columna 'AddressType' contenga 'interse'\n",
    "# df_filtrado = df[df[\"AddressType\"].str.contains(\"interse\", case=False, na=False)]\n",
    "\n",
    "# Mostrar solo la columna filtrada\n",
    "#  print(\"\\nValores √∫nicos en AddressType filtrados:\")\n",
    "\n",
    "# Convertir los valores √∫nicos en un DataFrame\n",
    "# df_unicos = pd.DataFrame(df_filtrado[\"AddressType\"].unique(), columns=[\"AddressType\"])\n",
    "# display(df_unicos)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c633ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "from difflib import get_close_matches\n",
    "\n",
    "# --- Funci√≥n de normalizaci√≥n b√°sica ---\n",
    "def normalizar_texto(texto):\n",
    "    if pd.isnull(texto):\n",
    "        return texto\n",
    "    texto = texto.lower().strip()\n",
    "    texto = ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', texto)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "    # quitar caracteres especiales no deseados\n",
    "    texto = re.sub(r\"[^a-z0-9\\s]\", \"\", texto)\n",
    "    return texto\n",
    "\n",
    "# --- Funci√≥n para unificar categor√≠as similares ---\n",
    "def unificar_categorias(serie, cutoff=0.8):\n",
    "    valores = serie.dropna().unique()\n",
    "    mapping = {}\n",
    "    for v in valores:\n",
    "        similares = get_close_matches(v, valores, cutoff=cutoff)\n",
    "        if len(similares) > 1:\n",
    "            # elegir el m√°s frecuente como \"est√°ndar\"\n",
    "            freq = serie.value_counts()\n",
    "            estandar = max(similares, key=lambda x: freq.get(x, 0))\n",
    "            for s in similares:\n",
    "                mapping[s] = estandar\n",
    "    # aplicar reemplazo\n",
    "    return serie.replace(mapping)\n",
    "\n",
    "# --- Aplicar a todas las columnas de texto ---\n",
    "for col in df.select_dtypes(include=\"object\").columns:\n",
    "    # normalizar texto\n",
    "    df[col] = df[col].apply(normalizar_texto)\n",
    "    # unificar categor√≠as similares\n",
    "    df[col] = unificar_categorias(df[col])\n",
    "\n",
    "# --- Reporte final ---\n",
    "print(\"\\n--- SOLUCI√ìN APLICADA ---\")\n",
    "print(\"1. Texto normalizado (min√∫sculas, sin acentos, sin caracteres especiales).\")\n",
    "print(\"2. Categor√≠as similares unificadas autom√°ticamente seg√∫n frecuencia.\")\n",
    "print(\"3. Aplicado en todas las columnas de texto.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3295b13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "from difflib import get_close_matches\n",
    "\n",
    "# ============================================\n",
    "# 6. Aplicaci√≥n de soluciones gen√©ricas\n",
    "# ============================================\n",
    "\n",
    "# Configuraci√≥n\n",
    "config = {\n",
    "    \"imputacion_numerica\": \"media\",\n",
    "    \"imputacion_categorica\": \"moda\",\n",
    "    \"formato_fecha\": \"%Y-%m-%d\",\n",
    "    \"deduplicar\": True,\n",
    "    \"validacion_rangos\": {\n",
    "        \"edad\": (0, 120),\n",
    "        \"precio\": (0, 10000)\n",
    "    },\n",
    "    \"conversion_unidades\": {\n",
    "        \"distancia_km\": (\"distancia_millas\", 0.621371)\n",
    "    }\n",
    "}\n",
    "\n",
    "# --- 6.1 Imputaci√≥n de valores nulos ---\n",
    "for col in df.select_dtypes(include=np.number).columns:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        if config[\"imputacion_numerica\"] == \"media\":\n",
    "            df[col].fillna(df[col].mean(), inplace=True)\n",
    "        elif config[\"imputacion_numerica\"] == \"mediana\":\n",
    "            df[col].fillna(df[col].median(), inplace=True)\n",
    "        elif config[\"imputacion_numerica\"] == \"cero\":\n",
    "            df[col].fillna(0, inplace=True)\n",
    "\n",
    "for col in df.select_dtypes(include=\"object\").columns:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        if config[\"imputacion_categorica\"] == \"moda\":\n",
    "            df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "        elif config[\"imputacion_categorica\"] == \"desconocido\":\n",
    "            df[col].fillna(\"desconocido\", inplace=True)\n",
    "\n",
    "# --- 6.2 Normalizaci√≥n de fechas ---\n",
    "for col in df.columns:\n",
    "    if \"fecha\" in col.lower():\n",
    "        try:\n",
    "            df[col] = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "            df[col] = df[col].dt.strftime(config[\"formato_fecha\"])\n",
    "        except Exception as e:\n",
    "            print(f\"No se pudo normalizar {col}: {e}\")\n",
    "\n",
    "# --- 6.3 Deduplicaci√≥n ---\n",
    "if config[\"deduplicar\"]:\n",
    "    df.drop_duplicates(inplace=True)\n",
    "\n",
    "# --- 6.4 Validaci√≥n de rangos ---\n",
    "for col, (min_val, max_val) in config[\"validacion_rangos\"].items():\n",
    "    if col in df.columns:\n",
    "        df.loc[(df[col] < min_val) | (df[col] > max_val), col] = np.nan\n",
    "\n",
    "# --- 6.5 Conversi√≥n de unidades ---\n",
    "for col, (new_col, factor) in config[\"conversion_unidades\"].items():\n",
    "    if col in df.columns:\n",
    "        df[new_col] = df[col] * factor\n",
    "\n",
    "# --- 6.6 Normalizaci√≥n de categor√≠as ---\n",
    "def normalizar_texto(texto):\n",
    "    if pd.isnull(texto): return texto\n",
    "    texto = texto.lower().strip()\n",
    "    texto = ''.join(c for c in unicodedata.normalize('NFD', texto) if unicodedata.category(c) != 'Mn')\n",
    "    texto = re.sub(r\"[^a-z0-9\\s]\", \"\", texto)\n",
    "    return texto\n",
    "\n",
    "# --- Funci√≥n gen√©rica para derivar valores desde otra columna ---\n",
    "def derivar_valor(texto):\n",
    "    if pd.isna(texto): return np.nan\n",
    "    s = str(texto).lower().strip()\n",
    "    # Ejemplo gen√©rico: extraer n√∫mero inicial\n",
    "    m = re.match(r\"^\\s*(\\d+)\\b\", s)\n",
    "    if m: return int(m.group(1))\n",
    "    # Ejemplo gen√©rico: detectar intersecciones\n",
    "    if \"/\" in s: return \"intersection\"\n",
    "    return np.nan\n",
    "\n",
    "# --- 1. Detectar columnas nulas o constantes ---\n",
    "cols_full_null = [c for c in df.columns if df[c].isna().all()]\n",
    "cols_constant = [c for c in df.columns if df[c].nunique(dropna=True) <= 1]\n",
    "\n",
    "print(\"Columnas 100% nulas:\", cols_full_null)\n",
    "print(\"Columnas constantes:\", cols_constant)\n",
    "\n",
    "# --- 2. Aplicar derivaci√≥n gen√©rica ---\n",
    "for col in cols_full_null:\n",
    "    # Intentar derivar desde Address si existe\n",
    "    if \"Address\" in df.columns:\n",
    "        df[col] = df[\"Address\"].apply(derivar_valor)\n",
    "        df[f\"has_{col}\"] = df[col].notna()\n",
    "\n",
    "# --- 3. Normalizaci√≥n de texto en todas las columnas categ√≥ricas ---\n",
    "for col in df.select_dtypes(include=\"object\").columns:\n",
    "    df[col] = df[col].apply(normalizar_texto)\n",
    "\n",
    "# --- 4. Unificaci√≥n de categor√≠as similares ---\n",
    "def unificar_categorias(serie, cutoff=0.8):\n",
    "    valores = serie.dropna().unique()\n",
    "    mapping = {}\n",
    "    for v in valores:\n",
    "        similares = get_close_matches(v, valores, cutoff=cutoff)\n",
    "        if len(similares) > 1:\n",
    "            freq = serie.value_counts()\n",
    "            estandar = max(similares, key=lambda x: freq.get(x, 0))\n",
    "            for s in similares:\n",
    "                mapping[s] = estandar\n",
    "    return serie.replace(mapping)\n",
    "\n",
    "for col in df.select_dtypes(include=\"object\").columns:\n",
    "    df[col] = unificar_categorias(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efd063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 7. Dataset limpio y reporte final\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n--- REPORTE DE SOLUCIONES APLICADAS ---\")\n",
    "print(\"1. Imputaci√≥n de valores nulos realizada.\")\n",
    "print(\"2. Fechas normalizadas al formato:\", config[\"formato_fecha\"])\n",
    "print(\"3. Deduplicaci√≥n aplicada:\", config[\"deduplicar\"])\n",
    "print(\"4. Validaci√≥n de rangos aplicada en columnas:\", list(config[\"validacion_rangos\"].keys()))\n",
    "print(\"5. Conversi√≥n de unidades aplicada en columnas:\", list(config[\"conversion_unidades\"].keys()))\n",
    "print(\"6. Normalizaci√≥n de texto y categor√≠as aplicada.\")\n",
    "print(\"7. Derivaci√≥n de 'Range' desde 'Address' aplicada.\")\n",
    "print(\"8. Normalizaci√≥n sem√°ntica de 'AdressTy' aplicada.\")\n",
    "print(\"\\nDimensiones finales del dataset:\", df.shape)\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0a938b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 4. Visualizaciones r√°pidas \n",
    "# ============================================\n",
    "\n",
    "# Mapa de valores nulos\n",
    "sns.heatmap(df.isnull(), cbar=False)\n",
    "plt.title(\"Mapa de valores nulos\")\n",
    "plt.show()\n",
    "\n",
    "# Boxplot solo para columnas num√©ricas con datos suficientes\n",
    "for col in num_cols:\n",
    "    if df[col].dropna().nunique() > 1:  # al menos dos valores distintos\n",
    "        plt.figure(figsize=(6,3))\n",
    "        sns.boxplot(x=df[col])\n",
    "        plt.title(f\"Outliers en {col}\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Columna '{col}' omitida: no tiene suficientes datos num√©ricos v√°lidos para graficar.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9224907b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar el DataFrame limpio a un nuevo CSV\n",
    "df.to_csv(\"dataset_limpio.csv\", index=False, encoding=\"utf-8\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
